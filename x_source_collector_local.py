#!/usr/bin/env python3
"""
Xè¨˜äº‹åé›†å™¨ - ãƒ­ãƒ¼ã‚«ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ç‰ˆ
"""

import re
import csv
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import hashlib
from pathlib import Path
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

try:
    from src.models.article import Article, TechnicalMetadata, BusinessMetadata, ImplementationCost
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®æœ€å°ãƒ¢ãƒ‡ãƒ«
    class Article:
        def __init__(self, **kwargs):
            for k, v in kwargs.items():
                setattr(self, k, v)

class XSourceCollectorLocal:
    """ãƒ­ãƒ¼ã‚«ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Xè¨˜äº‹ã‚’èª­ã¿è¾¼ã¿"""
    
    def __init__(self):
        self.csv_file_path = project_root / "å‚è€ƒ" / "x_articles.csv"
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
        self.default_articles = self.create_sample_x_articles()
    
    def create_sample_x_articles(self) -> List[Article]:
        """ã‚µãƒ³ãƒ—ãƒ«Xè¨˜äº‹ãƒ‡ãƒ¼ã‚¿"""
        sample_data = [
            {
                "created_at": "2025-01-23T10:00:00Z",
                "username": "AndrewYNg",
                "content": "RAG (Retrieval Augmented Generation) is revolutionizing how AI systems handle knowledge. New paper shows 40% improvement in factual accuracy. This could be the key to solving hallucinations in LLMs. #AI #MachineLearning",
                "link": "https://arxiv.org/abs/2501.12345",
                "tweet_url": "https://twitter.com/AndrewYNg/status/123456789"
            },
            {
                "created_at": "2025-01-23T14:30:00Z", 
                "username": "ylecun",
                "content": "Multimodal AI models are showing incredible progress. New Claude can now understand complex diagrams and generate code from sketches. The future of human-AI interaction is visual. ğŸ”¥",
                "link": "https://github.com/anthropics/claude-multimodal",
                "tweet_url": "https://twitter.com/ylecun/status/123456790"
            },
            {
                "created_at": "2025-01-23T16:15:00Z",
                "username": "karpathy",
                "content": "AI Agents are the next frontier. OpenAI's new agent framework can autonomously debug code, manage tasks, and even write documentation. We're moving from tools to colleagues. Thread ğŸ§µ",
                "link": "https://openai.com/blog/ai-agents-2025",
                "tweet_url": "https://twitter.com/karpathy/status/123456791"
            }
        ]
        
        articles = []
        for data in sample_data:
            article = self.create_article_from_data(data)
            if article:
                articles.append(article)
        
        return articles
    
    def parse_x_articles(self) -> List[Article]:
        """Xè¨˜äº‹ã‚’å–å¾—ãƒ»è§£æ"""
        articles = []
        
        print("ğŸ“¡ Xè¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        
        # ãƒ­ãƒ¼ã‚«ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
        if self.csv_file_path.exists():
            print(f"ğŸ“‚ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿: {self.csv_file_path}")
            articles = self.read_from_csv()
        else:
            print("ğŸ“‚ ãƒ­ãƒ¼ã‚«ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print(f"ğŸ’¡ æ¬¡ã®å ´æ‰€ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¦ãã ã•ã„: {self.csv_file_path}")
            print("ğŸ”¢ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: created_at,username,content,link,tweet_url")
            print("\nğŸ¯ ã‚µãƒ³ãƒ—ãƒ«Xè¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™...")
            articles = self.default_articles
        
        if articles:
            print(f"âœ… Xè¨˜äº‹åé›†å®Œäº†: {len(articles)}è¨˜äº‹")
        else:
            print("âš ï¸ Xè¨˜äº‹ã¯å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        return articles
    
    def read_from_csv(self) -> List[Article]:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        articles = []
        
        try:
            with open(self.csv_file_path, 'r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                
                for row in reader:
                    data = {
                        'created_at': row.get('created_at', ''),
                        'username': row.get('username', ''),
                        'content': row.get('content', ''),
                        'link': row.get('link', ''),
                        'tweet_url': row.get('tweet_url', '')
                    }
                    
                    article = self.create_article_from_data(data)
                    if article:
                        articles.append(article)
                        
        except Exception as e:
            print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
        return articles
    
    def create_article_from_data(self, data: Dict) -> Optional[Article]:
        """ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Articleã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ"""
        try:
            # æ—¥ä»˜è§£æ
            try:
                if 'T' in data['created_at']:
                    pub_date = datetime.fromisoformat(data['created_at'].replace('Z', '+00:00'))
                else:
                    pub_date = datetime.now()
            except:
                pub_date = datetime.now()
            
            # 3æ—¥ä»¥å†…ã®è¨˜äº‹ã®ã¿
            if pub_date < datetime.now() - timedelta(days=3):
                return None
            
            content = data['content']
            username = data['username']
            
            # AIãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if not self.is_ai_related(content):
                return None
            
            # è¨˜äº‹ä½œæˆ
            article_id = f"x_{hashlib.md5((username + content).encode()).hexdigest()[:8]}"
            
            article = Article(
                id=article_id,
                title=self.extract_title_from_post(content),
                url=data['link'] or data['tweet_url'],
                source=f"X(@{username})",
                source_tier=2,  # Xè¨˜äº‹ã¯ä¿¡é ¼æ€§tier 2
                published_date=pub_date,
                content=content[:300] + "..." if len(content) > 300 else content,
                tags=['x_post', 'community', 'ai_2025']
            )
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            article.technical = TechnicalMetadata(
                implementation_ready='github' in content.lower() or 'code' in content.lower(),
                code_available='github.com' in content.lower(),
                reproducibility_score=0.6
            )
            
            article.business = BusinessMetadata(
                market_size="ã‚°ãƒ­ãƒ¼ãƒãƒ«",
                growth_rate=70,
                implementation_cost=ImplementationCost.LOW
            )
            
            # è©•ä¾¡ã‚¹ã‚³ã‚¢
            ai_score = self.calculate_ai_relevance_score(content)
            article.evaluation = {
                "engineer": {"total_score": min(1.0, ai_score + 0.1)},
                "business": {"total_score": min(1.0, ai_score * 0.8)}
            }
            
            return article
            
        except Exception as e:
            print(f"âš ï¸ è¨˜äº‹ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
            return None
    
    def is_ai_related(self, content: str) -> bool:
        """AIé–¢é€£åˆ¤å®šï¼ˆ2025å¹´å¯¾å¿œï¼‰"""
        text = content.lower()
        
        ai_keywords = [
            'ai', 'artificial intelligence', 'machine learning', 'ml', 'deep learning',
            'neural network', 'llm', 'large language model', 'chatgpt', 'gpt-4', 'gpt-5',
            'claude', 'gemini', 'bard', 'llama', 'mistral', 'openai',
            'generative ai', 'gen ai', 'stable diffusion', 'midjourney', 'dall-e', 'sora',
            'rag', 'retrieval augmented generation', 'fine-tuning', 'multimodal',
            'ai agent', 'transformer', 'attention', 'foundation model'
        ]
        
        return any(keyword in text for keyword in ai_keywords)
    
    def extract_title_from_post(self, content: str) -> str:
        """æŠ•ç¨¿å†…å®¹ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º"""
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', content)
        if sentences and len(sentences[0]) <= 100:
            return sentences[0].strip()
        return content[:50] + "..." if len(content) > 50 else content
    
    def calculate_ai_relevance_score(self, content: str) -> float:
        """AIé–¢é€£åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        text = content.lower()
        
        high_value_keywords = ['gpt-4', 'claude', 'gemini', 'rag', 'multimodal', 'ai agent']
        score = 0.6
        
        for keyword in high_value_keywords:
            if keyword in text:
                score += 0.08
        
        if 'http' in content:
            score += 0.05
        
        return min(1.0, score)
    
    def create_sample_csv(self):
        """ã‚µãƒ³ãƒ—ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        self.csv_file_path.parent.mkdir(exist_ok=True)
        
        sample_csv_content = '''created_at,username,content,link,tweet_url
2025-01-23T10:00:00Z,AndrewYNg,"RAG (Retrieval Augmented Generation) is revolutionizing how AI systems handle knowledge. New paper shows 40% improvement in factual accuracy. #AI",https://arxiv.org/abs/2501.12345,https://twitter.com/AndrewYNg/status/123456789
2025-01-23T14:30:00Z,ylecun,"Multimodal AI models are showing incredible progress. New Claude can now understand complex diagrams and generate code from sketches. ğŸ”¥",https://github.com/anthropics/claude-multimodal,https://twitter.com/ylecun/status/123456790
2025-01-23T16:15:00Z,karpathy,"AI Agents are the next frontier. OpenAI's new agent framework can autonomously debug code and manage tasks. Thread ğŸ§µ",https://openai.com/blog/ai-agents-2025,https://twitter.com/karpathy/status/123456791'''
        
        with open(self.csv_file_path, 'w', encoding='utf-8') as f:
            f.write(sample_csv_content)
        
        print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {self.csv_file_path}")

def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    collector = XSourceCollectorLocal()
    
    # ã‚µãƒ³ãƒ—ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if not collector.csv_file_path.exists():
        print("ğŸ“ ã‚µãƒ³ãƒ—ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã‹ï¼Ÿ (y/n): ", end="")
        if input().lower().startswith('y'):
            collector.create_sample_csv()
    
    articles = collector.parse_x_articles()
    
    print(f"\nğŸ“Š Xè¨˜äº‹åé›†çµæœ:")
    print(f"  â€¢ ç·è¨˜äº‹æ•°: {len(articles)}")
    
    if articles:
        print(f"\nğŸ† ãƒˆãƒƒãƒ—5è¨˜äº‹:")
        for i, article in enumerate(articles[:5]):
            print(f"  {i+1}. {article.source} - {article.title}")
            print(f"     ã‚¹ã‚³ã‚¢: {article.evaluation['engineer']['total_score']:.2f}")

if __name__ == "__main__":
    main()