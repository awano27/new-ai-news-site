[
  {
    "id": "rss_b7fabe37",
    "title": "How to Import Pre-Annotated Data into Label Studio and Run the Full Stack with Docker | Towards Data Science",
    "url": "https://towardsdatascience.com/how-to-import-pre-annotated-data-into-label-studio-and-run-the-full-stack-with-docker/",
    "source": "Towards Data Science",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "From VOC to JSON: Importing pre-annotations made simple",
    "sourceDomain": "towardsdatascience.com"
  },
  {
    "id": "rss_ebbc1fa8",
    "title": "Unlocking Multimodal Video Transcription with Gemini | Towards Data Science",
    "url": "https://towardsdatascience.com/unlocking-multimodal-video-transcription-with-gemini/",
    "source": "Towards Data Science",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Explore how to transcribe videos with speaker identification in a single prompt",
    "sourceDomain": "towardsdatascience.com"
  },
  {
    "id": "rss_8d151cf4",
    "title": "Toward Digital Well-Being: Using Generative AI to Detect and Mitigate Bias in Social Networks | Towards Data Science",
    "url": "https://towardsdatascience.com/toward-digital-well-being-using-generative-ai-to-detect-and-mitigate-bias-in-social-networks/",
    "source": "Towards Data Science",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "This research answered the question: How can machine learning and artificial intelligence help us to unlearn bias?",
    "sourceDomain": "towardsdatascience.com"
  },
  {
    "id": "rss_a6407d0e",
    "title": "Marginal Effect of Hyperparameter Tuning with XGBoost | Towards Data Science",
    "url": "https://towardsdatascience.com/marginal-effect-of-hyperparameter-tuning-with-xgboost/",
    "source": "Towards Data Science",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Demystifying Bayesian hyperparameter optimization and comparing hyperparameter tuning paradigms",
    "sourceDomain": "towardsdatascience.com"
  },
  {
    "id": "rss_daf11528",
    "title": "Overview of BioASQ 2024: The twelfth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering",
    "url": "https://arxiv.org/abs/2508.20532",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "This is an overview of the twelfth edition of the BioASQ challenge in the context of the Conference and Labs of the Evaluation Forum (CLEF) 2024. BioASQ is a series of international challenges promoting advances in large-scale biomedical semantic indexing and question answering. This year, BioASQ…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf114ec",
    "title": "SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM",
    "url": "https://arxiv.org/abs/2508.20514",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Topic discovery in scientific literature provides valuable insights for researchers to identify emerging trends and explore new avenues for investigation, facilitating easier scientific information retrieval. Many machine learning methods, particularly deep embedding techniques, have been applied…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf114e9",
    "title": "Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark",
    "url": "https://arxiv.org/abs/2508.20511",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Multilingual machine translation (MT) benchmarks play a central role in evaluating the capabilities of modern MT systems. Among them, the FLORES+ benchmark is widely used, offering English-to-many translation data for over 200 languages, curated with strict quality control protocols. However, we …",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf111ca",
    "title": "ConspirED: A Dataset for Cognitive Traits of Conspiracy Theories and Large Language Model Safety",
    "url": "https://arxiv.org/abs/2508.20468",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Conspiracy theories erode public trust in science and institutions while resisting debunking by evolving and absorbing counter-evidence. As AI-generated misinformation becomes increasingly sophisticated, understanding rhetorical patterns in conspiratorial content is important for developing inter…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf111c2",
    "title": "Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques",
    "url": "https://arxiv.org/abs/2508.20460",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Background Predicting mortality and resource utilization from electronic health records (EHRs) is challenging yet crucial for optimizing patient outcomes and managing costs in intensive care unit (ICU). Existing approaches predominantly focus on structured EHRs, often ignoring the valuable clinic…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf111a6",
    "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers",
    "url": "https://arxiv.org/abs/2508.20453",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "We introduce MCP-Bench, a benchmark for evaluating large language models (LLMs) on realistic, multi-step tasks that demand tool use, cross-tool coordination, precise parameter control, and planning/reasoning for solving tasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to …",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf11186",
    "title": "Searching the Title of Practical Work of the Informatics Engineering Bachelor Program with the Case Base Reasoning Method",
    "url": "https://arxiv.org/abs/2508.20442",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Case Base Reasoning (CBR) is a case solving technique based on experience in cases that have occurred before with the highest similarity. CBR is used to search for practical work titles. TF-IDF is applied to process the vectorization of each practical work title word and Cosine Similarity for the…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf11146",
    "title": "CAMB: A comprehensive industrial LLM benchmark on civil aviation maintenance",
    "url": "https://arxiv.org/abs/2508.20420",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Civil aviation maintenance is a domain characterized by stringent industry standards. Within this field, maintenance procedures and troubleshooting represent critical, knowledge-intensive tasks that require sophisticated reasoning. To address the lack of specialized evaluation tools for large lan…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf1112e",
    "title": "KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval",
    "url": "https://arxiv.org/abs/2508.20417",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "The integration of knowledge graphs (KGs) with large language models (LLMs) offers significant potential to improve the retrieval phase of retrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR, a novel framework for Contextual Query Retrieval (CQR) that enhances the retri…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf1112d",
    "title": "DentalBench: Benchmarking and Advancing LLMs Capability for Bilingual Dentistry Understanding",
    "url": "https://arxiv.org/abs/2508.20416",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Recent advances in large language models (LLMs) and medical LLMs (Med-LLMs) have demonstrated strong performance on general medical benchmarks. However, their capabilities in specialized medical fields, such as dentistry which require deeper domain-specific knowledge, remain underexplored due to …",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf11127",
    "title": "UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools",
    "url": "https://arxiv.org/abs/2508.20410",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "AI text-to-app tools promise high quality applications and websites in minutes, yet no public benchmark rigorously verifies those claims. We introduce UI-Bench, the first large-scale benchmark that evaluates visual excellence across competing AI text-to-app tools through expert pairwise compariso…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf10e63",
    "title": "Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction",
    "url": "https://arxiv.org/abs/2508.20395",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Recent advancements in large language models (LLMs) often rely on generating intermediate reasoning steps to enhance accuracy. However, little work has examined how reasoning utility contributes to the final answer's correctness. Due to the stochastic nature of autoregressive generation, generati…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf10e44",
    "title": "CAPE: Context-Aware Personality Evaluation Framework for Large Language Models",
    "url": "https://arxiv.org/abs/2508.20385",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Psychometric tests, traditionally used to assess humans, are now being applied to Large Language Models (LLMs) to evaluate their behavioral traits. However, existing studies follow a context-free approach, answering each question in isolation to avoid contextual influence. We term this the Disney…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf10e23",
    "title": "Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems",
    "url": "https://arxiv.org/abs/2508.20373",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Reasoning Large Language Models (RLLMs) have recently achieved remarkable progress on complex reasoning tasks, largely enabled by their long chain-of-thought (Long CoT) capabilities. However, developing these Long CoT behaviors relies heavily on post-training with high-quality datasets, which are…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf10de3",
    "title": "Joint Enhancement of Relational Reasoning for Long-Context LLMs",
    "url": "https://arxiv.org/abs/2508.20351",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Despite significant progress, large language models (LLMs) still struggle with long contexts due to memory limitations and their inability to tackle complex and long-context tasks. Additionally, LLMs often suffer from a lack of transparency and are prone to producing hallucinations. To address th…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf10d8a",
    "title": "GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs",
    "url": "https://arxiv.org/abs/2508.20325",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "As Large Language Models become increasingly integral to various domains, their potential to generate harmful responses has prompted significant societal and regulatory concerns. In response, governments have issued ethics guidelines to promote the development of trustworthy AI. However, these gu…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf10d89",
    "title": "Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities",
    "url": "https://arxiv.org/abs/2508.20324",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Reinforcement Learning has emerged as a post-training approach to elicit agentic RAG behaviors such as search and planning from language models. However, compact language models (e.g., 0.5B parameters) struggle due to poor reasoning ability, resulting in sparse rewards and unstable training. To o…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf109c7",
    "title": "Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach",
    "url": "https://arxiv.org/abs/2508.20223",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "The growing complexity of cyber-physical systems, particularly in automotive applications, has increased the demand for efficient modeling and cross-domain co-simulation techniques. While SystemC Transaction-Level Modeling (TLM) enables effective hardware/software co-design, its limited interoper…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf109ac",
    "title": "Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models",
    "url": "https://arxiv.org/abs/2508.20217",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "This study explores automatic generation (AIG) using language models to create multiple choice questions (MCQs) for morphological assessment, aiming to reduce the cost and inconsistency of manual test development. The study used a two-fold approach. First, we compared a fine-tuned medium model (G…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_daf10987",
    "title": "Social Bias in Multilingual Language Models: A Survey",
    "url": "https://arxiv.org/abs/2508.20201",
    "source": "arXiv cs.CL",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Pretrained multilingual models exhibit the same social bias as models processing English texts. This systematic review analyzes emerging research that extends bias evaluation and mitigation approaches into multilingual and non-English contexts. We examine these studies with respect to linguistic …",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f6d7",
    "title": "Dynamic Synthetic Controls vs. Panel-Aware Double Machine Learning for Geo-Level Marketing Impact Estimation",
    "url": "https://arxiv.org/abs/2508.20335",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Accurately quantifying geo-level marketing lift in two-sided marketplaces is challenging: the Synthetic Control Method (SCM) often exhibits high power yet systematically under-estimates effect size, while panel-style Double Machine Learning (DML) is seldom benchmarked against SCM. We build an ope…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f6d5",
    "title": "Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs",
    "url": "https://arxiv.org/abs/2508.20333",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Large Language Models (LLMs) are aligned to meet ethical standards and safety requirements by training them to refuse answering harmful or unsafe prompts. In this paper, we demonstrate how adversaries can exploit LLMs' alignment to implant bias, or enforce targeted censorship without degrading th…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f6d2",
    "title": "FORGE: Foundational Optimization Representations from Graph Embeddings",
    "url": "https://arxiv.org/abs/2508.20330",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Combinatorial optimization problems are ubiquitous in science and engineering, yet learning-based approaches to accelerate their solution often require solving a large number of hard-to-solve optimization instances to collect training data, incurring significant computational overhead. Existing m…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f6bb",
    "title": "Multi-View Graph Convolution Network for Internal Talent Recommendation Based on Enterprise Emails",
    "url": "https://arxiv.org/abs/2508.20328",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Internal talent recommendation is a critical strategy for organizational continuity, yet conventional approaches suffer from structural limitations, often overlooking qualified candidates by relying on the narrow perspective of a few managers. To address this challenge, we propose a novel framewo…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f699",
    "title": "Multi-Agent Reinforcement Learning in Intelligent Transportation Systems: A Comprehensive Survey",
    "url": "https://arxiv.org/abs/2508.20315",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "The growing complexity of urban mobility and the demand for efficient, sustainable, and adaptive solutions have positioned Intelligent Transportation Systems (ITS) at the forefront of modern infrastructure innovation. At the core of ITS lies the challenge of autonomous decision-making across dyna…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f3d0",
    "title": "FedReFT: Federated Representation Fine-Tuning with All-But-Me Aggregation",
    "url": "https://arxiv.org/abs/2508.20295",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Parameter-efficient fine-tuning (PEFT) has attracted significant attention for adapting large pre-trained models by modifying a small subset of parameters. Recently, Representation Fine-tuning (ReFT) has emerged as an effective alternative. ReFT shifts the fine-tuning paradigm from updating model…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f3cf",
    "title": "Dynamics-Aligned Latent Imagination in Contextual World Models for Zero-Shot Generalization",
    "url": "https://arxiv.org/abs/2508.20294",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Real-world reinforcement learning demands adaptation to unseen environmental conditions without costly retraining. Contextual Markov Decision Processes (cMDP) model this challenge, but existing methods often require explicit context variables (e.g., friction, gravity), limiting their use when con…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f3ce",
    "title": "Beacon: Post-Training Quantization with Integrated Grid Selection",
    "url": "https://arxiv.org/abs/2508.20293",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Quantization is a widely used compression technique for reducing the memory and computation costs of large pre-trained models. A key challenge in per-channel post-training quantization (PTQ) is selecting appropriate scaling factors to replace weight values with values from a scaled quantization g…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f3cb",
    "title": "Objective Value Change and Shape-Based Accelerated Optimization for the Neural Network Approximation",
    "url": "https://arxiv.org/abs/2508.20290",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "This paper introduce a novel metric of an objective function f, we say VC (value change) to measure the difficulty and approximation affection when conducting an neural network approximation task, and it numerically supports characterizing the local performance and behavior of neural network appr…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f392",
    "title": "A Systematic Review on the Generative AI Applications in Human Medical Genomics",
    "url": "https://arxiv.org/abs/2508.20275",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Although traditional statistical techniques and machine learning methods have contributed significantly to genetics and, in particular, inherited disease diagnosis, they often struggle with complex, high-dimensional data, a challenge now addressed by state-of-the-art deep learning models. Large l…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f36e",
    "title": "Generalizable AI Model for Indoor Temperature Forecasting Across Sub-Saharan Africa",
    "url": "https://arxiv.org/abs/2508.20260",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "This study presents a lightweight, domain-informed AI model for predicting indoor temperatures in naturally ventilated schools and homes in Sub-Saharan Africa. The model extends the Temp-AI-Estimator framework, trained on Tanzanian school data, and evaluated on Nigerian schools and Gambian homes.…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f358",
    "title": "Latent Variable Modeling for Robust Causal Effect Estimation",
    "url": "https://arxiv.org/abs/2508.20259",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Latent variable models provide a powerful framework for incorporating and inferring unobserved factors in observational data. In causal inference, they help account for hidden factors influencing treatment or outcome, thereby addressing challenges posed by missing or unmeasured covariates. This p…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f356",
    "title": "Discovering equations from data: symbolic regression in dynamical systems",
    "url": "https://arxiv.org/abs/2508.20257",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "The process of discovering equations from data lies at the heart of physics and in many other areas of research, including mathematical ecology and epidemiology. Recently, machine learning methods known as symbolic regression have automated this process. As several methods are available in the li…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f353",
    "title": "Beyond Optimization: Exploring Novelty Discovery in Autonomous Experiments",
    "url": "https://arxiv.org/abs/2508.20254",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Autonomous experiments (AEs) are transforming how scientific research is conducted by integrating artificial intelligence with automated experimental platforms. Current AEs primarily focus on the optimization of a predefined target; while accelerating this goal, such an approach limits the discov…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f312",
    "title": "Bounds on Perfect Node Classification: A Convex Graph Clustering Perspective",
    "url": "https://arxiv.org/abs/2508.20231",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "We present an analysis of the transductive node classification problem, where the underlying graph consists of communities that agree with the node labels and node features. For node classification, we propose a novel optimization problem that incorporates the node-specific information (labels an…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f311",
    "title": "Coresets from Trajectories: Selecting Data via Correlation of Loss Differences",
    "url": "https://arxiv.org/abs/2508.20230",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Deep learning models achieve state-of-the-art performance across domains but face scalability challenges in real-time or resource-constrained scenarios. To address this, we propose Correlation of Loss Differences (CLD), a simple and scalable metric for coreset selection that identifies the most i…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f2f6",
    "title": "The Role of Teacher Calibration in Knowledge Distillation",
    "url": "https://arxiv.org/abs/2508.20224",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Knowledge Distillation (KD) has emerged as an effective model compression technique in deep learning, enabling the transfer of knowledge from a large teacher model to a compact student model. While KD has demonstrated significant success, it is not yet fully understood which factors contribute to…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f2d4",
    "title": "What can we learn from signals and systems in a transformer? Insights for probabilistic modeling and inference architecture",
    "url": "https://arxiv.org/abs/2508.20211",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "In the 1940s, Wiener introduced a linear predictor, where the future prediction is computed by linearly combining the past data. A transformer generalizes this idea: it is a nonlinear predictor where the next-token prediction is computed by nonlinearly combining the past tokens. In this essay, we…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0f2ba",
    "title": "Filter then Attend: Improving attention-based Time Series Forecasting with Spectral Filtering",
    "url": "https://arxiv.org/abs/2508.20206",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Transformer-based models are at the forefront in long time-series forecasting (LTSF). While in many cases, these models are able to achieve state of the art results, they suffer from a bias toward low-frequencies in the data and high computational and memory requirements. Recent work has establis…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_46f0ef72",
    "title": "CrystalICL: Enabling In-Context Learning for Crystal Generation",
    "url": "https://arxiv.org/abs/2508.20143",
    "source": "arXiv cs.LG",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Designing crystal materials with desired physicochemical properties remains a fundamental challenge in materials science. While large language models (LLMs) have demonstrated strong in-context learning (ICL) capabilities, existing LLM-based crystal generation approaches are limited to zero-shot s…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_55e05168",
    "title": "Single Agent Robust Deep Reinforcement Learning for Bus Fleet Control",
    "url": "https://arxiv.org/abs/2508.20784",
    "source": "arXiv cs.AI",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Bus bunching remains a challenge for urban transit due to stochastic traffic and passenger demand. Traditional solutions rely on multi-agent reinforcement learning (MARL) in loop-line settings, which overlook realistic operations characterized by heterogeneous routes, timetables, fluctuating dema…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_55e050b3",
    "title": "Re4: Scientific Computing Agent with Rewriting, Resolution, Review and Revision",
    "url": "https://arxiv.org/abs/2508.20729",
    "source": "arXiv cs.AI",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Large language models (LLMs) serve as an active and promising field of generative artificial intelligence and have demonstrated abilities to perform complex tasks in multiple domains, including mathematical and scientific reasoning. In this work, we construct a novel agent framework for solving r…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_55e0506d",
    "title": "Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings",
    "url": "https://arxiv.org/abs/2508.20701",
    "source": "arXiv cs.AI",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "The paper introduces a novel framework based on category theory to enhance the explainability of artificial intelligence systems, particularly focusing on word embeddings. Key topics include the construction of categories $ Ł_{T} $ and $ ¶_{T} $, providing schematic representations of the semanti…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_55e04d88",
    "title": "Bridging Minds and Machines: Toward an Integration of AI and Cognitive Science",
    "url": "https://arxiv.org/abs/2508.20674",
    "source": "arXiv cs.AI",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Cognitive Science has profoundly shaped disciplines such as Artificial Intelligence (AI), Philosophy, Psychology, Neuroscience, Linguistics, and Culture. Many breakthroughs in AI trace their roots to cognitive theories, while AI itself has become an indispensable tool for advancing cognitive rese…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_55e049cb",
    "title": "Human-AI Collaborative Bot Detection in MMORPGs",
    "url": "https://arxiv.org/abs/2508.20578",
    "source": "arXiv cs.AI",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "In Massively Multiplayer Online Role-Playing Games (MMORPGs), auto-leveling bots exploit automated programs to level up characters at scale, undermining gameplay balance and fairness. Detecting such bots is challenging, not only because they mimic human behavior, but also because punitive actions…",
    "sourceDomain": "arxiv.org"
  },
  {
    "id": "rss_55e0492d",
    "title": "Enhancing Health Fact-Checking with LLM-Generated Synthetic Data",
    "url": "https://arxiv.org/abs/2508.20525",
    "source": "arXiv cs.AI",
    "publishedAt": "2025-08-29",
    "tags": [
      "rss_feed"
    ],
    "summary": "Fact-checking for health-related content is challenging due to the limited availability of annotated training data. In this study, we propose a synthetic data generation pipeline that leverages large language models (LLMs) to augment training data for health-related fact checking. In this pipelin…",
    "sourceDomain": "arxiv.org"
  }
]