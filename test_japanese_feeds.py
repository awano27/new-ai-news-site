#!/usr/bin/env python3
"""æ—¥æœ¬èªãƒ•ã‚£ãƒ¼ãƒ‰ã®æ¥ç¶šãƒ†ã‚¹ãƒˆ"""

import requests
import feedparser

def test_japanese_feeds():
    """æ—¥æœ¬èªãƒ•ã‚£ãƒ¼ãƒ‰ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ"""
    
    feeds = {
        "ITmedia AI": "https://rss.itmedia.co.jp/rss/2.0/ait.xml",
        "ITmedia ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼": "https://rss.itmedia.co.jp/rss/2.0/news_technology.xml",
        "PC Watch": "https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf",
        "INTERNET Watch": "https://internet.watch.impress.co.jp/data/rss/1.0/iw/feed.rdf",
        "CNET Japan": "https://feeds.japan.cnet.com/rss/cnet/all.rdf",
        "Gizmodo Japan": "https://www.gizmodo.jp/index.xml",
        "TechCrunch Japan": "https://jp.techcrunch.com/feed/",
        "ãƒã‚¤ãƒŠãƒ“ãƒ†ãƒƒã‚¯+": "https://news.mynavi.jp/rss/techplus"
    }
    
    print("ğŸ” æ—¥æœ¬èªãƒ•ã‚£ãƒ¼ãƒ‰ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ")
    print("=" * 40)
    
    results = {}
    
    for name, url in feeds.items():
        try:
            print(f"\nğŸ“¡ ãƒ†ã‚¹ãƒˆä¸­: {name}")
            print(f"URL: {url}")
            
            headers = {
                'User-Agent': 'DailyAINews/1.0 (Educational Project)',
                'Accept': 'application/rss+xml, application/xml'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
            
            if response.status_code == 200:
                # ãƒ•ã‚£ãƒ¼ãƒ‰è§£æãƒ†ã‚¹ãƒˆ
                feed = feedparser.parse(response.content)
                entries_count = len(feed.entries) if hasattr(feed, 'entries') else 0
                
                print(f"âœ… æˆåŠŸ - ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ•°: {entries_count}")
                
                if entries_count > 0:
                    latest = feed.entries[0]
                    print(f"æœ€æ–°è¨˜äº‹: {latest.title[:50]}...")
                    results[name] = {'status': 'success', 'entries': entries_count, 'latest': latest.title}
                else:
                    results[name] = {'status': 'no_entries', 'entries': 0}
            else:
                print(f"âŒ HTTPã‚¨ãƒ©ãƒ¼: {response.status_code}")
                results[name] = {'status': 'http_error', 'code': response.status_code}
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
            results[name] = {'status': 'error', 'error': str(e)[:100]}
    
    print(f"\nğŸ“Š çµæœã‚µãƒãƒªãƒ¼:")
    print("-" * 30)
    
    success_count = 0
    for name, result in results.items():
        status_icon = "âœ…" if result['status'] == 'success' else "âŒ"
        print(f"{status_icon} {name}: {result['status']}")
        if result['status'] == 'success':
            success_count += 1
    
    print(f"\nğŸ“ˆ æˆåŠŸç‡: {success_count}/{len(feeds)} ({success_count/len(feeds)*100:.0f}%)")
    
    return results

if __name__ == "__main__":
    print("ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªAIãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚£ãƒ¼ãƒ‰æ¥ç¶šãƒ†ã‚¹ãƒˆ")
    
    try:
        results = test_japanese_feeds()
        
        # åˆ©ç”¨å¯èƒ½ãªã‚½ãƒ¼ã‚¹ã‚’ãƒ¬ãƒãƒ¼ãƒˆ
        available = [name for name, result in results.items() if result['status'] == 'success']
        
        if available:
            print(f"\nâœ… åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªã‚½ãƒ¼ã‚¹: {len(available)}å€‹")
            for name in available:
                print(f"  â€¢ {name}")
            
            print(f"\nğŸ’¡ ã“ã‚Œã‚‰ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰æ—¥æœ¬èªè¨˜äº‹ã‚’åé›†ã§ãã¾ã™ï¼")
            print(f"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: python collect_japanese_sources.py")
        else:
            print(f"\nâš ï¸ ç¾åœ¨åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªã‚½ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“")
            print(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã¾ãŸã¯ãƒ•ã‚£ãƒ¼ãƒ‰URLã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    input("\nEnterã‚’æŠ¼ã—ã¦çµ‚äº†...")